## CSE580 Final Project --- Anticipating and Mitigating the Risks of LLMs on Misinformation: A Case Study on Social Media Bots

<div align="center">
  <b>Shangbin Feng*, Yike Wang*</b>
</div>

### 
**Abstract**: The battle between social media bot detectors and bots designed to evade detection has been ongoing. In this research, we explore
how advanced language models (LLMs) can be used to both improve bot detection and create more sophisticated bots. To improve
detection, we developed a new method that combines different types of user information to better identify bots. Our experiments
showed that LLMs, even with limited training data, significantly outperformed existing methods. However, we also found that LLMs
can be used to create more effective bots that can evade detection. These bots can manipulate both text and structured information,
making it harder to identify them. This highlights the potential dangers of LLMs in the context of social media and the need for
continued research to stay ahead of these evolving threats.
